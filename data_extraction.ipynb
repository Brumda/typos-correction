{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports",
   "id": "d86d6a8b8b5422fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Functions",
   "id": "71c1955c8e2e5c1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_df(data):\n",
    "    rows = []\n",
    "    for commit in data.edits:\n",
    "        for edit in commit:\n",
    "            if edit[\"src\"][\"lang\"] == \"eng\" and edit[\"is_typo\"]:\n",
    "                text = edit[\"src\"][\"text\"]\n",
    "                target = edit[\"tgt\"][\"text\"]\n",
    "                rows.append({\"text\": text, \"target\": target})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def write_column_to_file(series, filename):\n",
    "    with open(filename, 'w', encoding='utf-8', buffering=8192) as f:\n",
    "        for chunk in series.astype(str):\n",
    "            f.write(chunk.strip() + '\\n')\n",
    "\n",
    "\n",
    "def count_lines(filename):\n",
    "    with open(filename, 'r', encoding='utf-8', newline='\\n') as f:\n",
    "        return sum(1 for _ in f)"
   ],
   "id": "c3d5b0d02cbd1ce6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data extraction",
   "id": "5c294658e43a723a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "path = \"typo_corpus/github-typo-corpus.v1.0.0.jsonl\"\n",
    "data = pd.read_json(path, lines=True)"
   ],
   "id": "7551204f87453941"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = get_df(data)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(df.text, df.target, test_size=0.2, random_state=42)\n",
    "print(f\"Train dimension, X: {Xtrain.shape}, y: {ytrain.shape}\")\n",
    "print(f\"Test dimension, X: {Xtest.shape}, y: {ytest.shape}\")"
   ],
   "id": "a2832946702bbb98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "write_column_to_file(Xtrain, 'train_corrupt.txt')\n",
    "write_column_to_file(ytrain, 'train_clean.txt')\n",
    "write_column_to_file(Xtest, 'test_corrupt.txt')\n",
    "write_column_to_file(ytest, 'test_clean.txt')"
   ],
   "id": "b9415ecb7d02a54c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lines_train_corrupt = count_lines('train_corrupt.txt')\n",
    "lines_train_clean = count_lines('train_clean.txt')\n",
    "lines_test_corrupt = count_lines('test_corrupt.txt')\n",
    "lines_test_clean = count_lines('test_clean.txt')\n",
    "print(f\"Train lines match: {lines_train_corrupt == lines_train_clean}\")\n",
    "print(f\"Test lines match: {lines_test_corrupt == lines_test_clean}\")\n",
    "print(f\"Train lines: {lines_train_corrupt}\")\n",
    "print(f\"Test lines: {lines_test_corrupt}\")"
   ],
   "id": "11b3f0ede01909b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "95d927300d5bac4e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
