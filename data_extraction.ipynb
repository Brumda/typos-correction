{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports",
   "id": "d86d6a8b8b5422fa"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-27T18:46:05.517256Z",
     "start_time": "2025-02-27T18:46:00.122365Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Functions",
   "id": "71c1955c8e2e5c1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:47:29.985973Z",
     "start_time": "2025-02-27T18:47:29.982121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_df(_data):\n",
    "    rows = []\n",
    "    for commit in _data.edits:\n",
    "        for edit in commit:\n",
    "            if edit[\"src\"][\"lang\"] == \"eng\" and edit[\"is_typo\"]:\n",
    "                text = edit[\"src\"][\"text\"]\n",
    "                target = edit[\"tgt\"][\"text\"]\n",
    "                rows.append({\"text\": text, \"target\": target})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def write_column_to_file(series, filename, separator='\\n'):\n",
    "    with open(filename, 'w', encoding='utf-8', buffering=8192) as f:\n",
    "        for chunk in series.astype(str):\n",
    "            f.write(chunk.strip() + separator)\n",
    "\n",
    "\n",
    "def count_lines(filename):\n",
    "    with open(filename, 'r', encoding='utf-8', newline='\\n') as f:\n",
    "        return sum(1 for _ in f)"
   ],
   "id": "c3d5b0d02cbd1ce6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data extraction",
   "id": "5c294658e43a723a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:46:13.860933Z",
     "start_time": "2025-02-27T18:46:10.736264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# https://github-typo-corpus.s3.amazonaws.com/data/github-typo-corpus.v1.0.0.jsonl.gz\n",
    "path = \"typo_corpus/github-typo-corpus.v1.0.0.jsonl\"\n",
    "data = pd.read_json(path, lines=True)"
   ],
   "id": "7551204f87453941",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:46:15.502110Z",
     "start_time": "2025-02-27T18:46:15.203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = get_df(data)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(df.text, df.target, test_size=0.2, random_state=42)\n",
    "print(f\"Train dimension, X: {Xtrain.shape}, y: {ytrain.shape}\")\n",
    "print(f\"Test dimension, X: {Xtest.shape}, y: {ytest.shape}\")"
   ],
   "id": "a2832946702bbb98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimension, X: (204044,), y: (204044,)\n",
      "Test dimension, X: (51012,), y: (51012,)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T18:47:33.621440Z",
     "start_time": "2025-02-27T18:47:33.541486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATAPATH = \"./data/\"\n",
    "write_column_to_file(ytrain, DATAPATH + 'corpus.txt', separator=' ')"
   ],
   "id": "1c945a32151f7359",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T15:30:30.947673Z",
     "start_time": "2025-02-22T15:30:30.649261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATAPATH = \"./data/\"\n",
    "write_column_to_file(Xtrain, DATAPATH + 'train_corrupt.txt')\n",
    "write_column_to_file(ytrain, DATAPATH + 'train_clean.txt')\n",
    "write_column_to_file(Xtest, DATAPATH + 'test_corrupt.txt')\n",
    "write_column_to_file(ytest, DATAPATH + 'test_clean.txt')"
   ],
   "id": "b9415ecb7d02a54c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T15:31:11.288395Z",
     "start_time": "2025-02-22T15:31:11.187282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lines_train_corrupt = count_lines(DATAPATH + 'train_corrupt.txt')\n",
    "lines_train_clean = count_lines(DATAPATH + 'train_clean.txt')\n",
    "lines_test_corrupt = count_lines(DATAPATH + 'test_corrupt.txt')\n",
    "lines_test_clean = count_lines(DATAPATH + 'test_clean.txt')\n",
    "print(f\"Train lines match: {lines_train_corrupt == lines_train_clean}\")\n",
    "print(f\"Test lines match: {lines_test_corrupt == lines_test_clean}\")\n",
    "print(f\"Train lines: {lines_train_corrupt}, is same as train dimension: {lines_train_clean == Xtrain.shape[0]}\")\n",
    "print(f\"Test lines: {lines_test_corrupt}, is same as test dimension: {lines_test_clean == Xtest.shape[0]}\")"
   ],
   "id": "11b3f0ede01909b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train lines match: True\n",
      "Test lines match: True\n",
      "Train lines: 204044, is same as train dimension: True\n",
      "Test lines: 51012, is same as test dimension: True\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "95d927300d5bac4e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
